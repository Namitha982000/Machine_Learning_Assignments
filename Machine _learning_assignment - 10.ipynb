{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5aa79e8a-964a-4514-bb56-001a21e7cbf4",
   "metadata": {},
   "source": [
    "# Assignment - 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bc03b3-1d68-47f5-b2dc-f94c26182a34",
   "metadata": {},
   "source": [
    "**1. Define the Bayesian interpretation of probability.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9badb5e-4094-4fd8-8712-7b6d0ccbd0df",
   "metadata": {},
   "source": [
    "The Bayesian interpretation of probability is a philosophical and statistical framework that views probability as a measure of uncertainty or subjective belief rather than as a frequency or long-term relative frequency of events. It is based on the principles of Bayes' theorem and Bayesian inference.\n",
    "\n",
    "In the Bayesian interpretation, probability represents an individual's degree of belief or confidence in the occurrence of an event, given the available evidence or information. It incorporates prior knowledge or beliefs about the event, which are updated or revised based on new evidence or data.\n",
    "\n",
    "Bayes' theorem mathematically relates the prior probability (P(A)), the likelihood of observing the data given the hypothesis (P(D|A)), the prior probability of the data (P(D)), and the posterior probability (P(A|D)):\n",
    "\n",
    "P(A|D) = (P(D|A) * P(A)) / P(D)\n",
    "\n",
    "This theorem allows for the calculation of the posterior probability, which represents the updated belief in the hypothesis given the observed data.\n",
    "\n",
    "The Bayesian interpretation emphasizes the iterative nature of probability, where beliefs are updated as new evidence is obtained. It provides a framework for reasoning under uncertainty and is widely used in various fields, including statistics, machine learning, and decision theory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18195751-c79a-4389-8b17-72366d0021f0",
   "metadata": {},
   "source": [
    "**2. Define probability of a union of two events with equation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c3c3d1-8c52-4a5b-886b-998420912906",
   "metadata": {},
   "source": [
    "The probability of the union of two events, denoted as P(A ∪ B), is the probability that at least one of the two events A or B occurs. It can be calculated using the following equation:\n",
    "\n",
    "P(A ∪ B) = P(A) + P(B) - P(A ∩ B)\n",
    "\n",
    "In this equation:\n",
    "- P(A) represents the probability of event A occurring.\n",
    "- P(B) represents the probability of event B occurring.\n",
    "- P(A ∩ B) represents the probability of both events A and B occurring simultaneously (the intersection of A and B).\n",
    "\n",
    "To find the probability of the union of two events, we add the individual probabilities of the events A and B and subtract the probability of their intersection to avoid double-counting. This adjustment accounts for the overlap between the two events.\n",
    "\n",
    "It's important to note that this equation assumes the events A and B are mutually exclusive, meaning they cannot occur at the same time. If the events are not mutually exclusive, the equation would need to be modified to account for the overlapping probability more accurately.\n",
    "\n",
    "The formula for the probability of the union of two events is a fundamental concept in probability theory and is used to calculate the overall probability of multiple events occurring together or independently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8a89da-2364-4890-96f5-ce25bbd6372c",
   "metadata": {},
   "source": [
    "**3. What is joint probability? What is its formula?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825370c6-a65b-4072-9e58-559d2df300eb",
   "metadata": {},
   "source": [
    "Joint probability is a measure of the probability of two or more events occurring simultaneously. It quantifies the likelihood of the intersection of multiple events. The joint probability of events A and B is denoted as P(A ∩ B) or P(A, B).\n",
    "\n",
    "The formula for joint probability depends on whether the events A and B are independent or dependent:\n",
    "\n",
    "1. Independent Events:\n",
    "If events A and B are independent, meaning the occurrence of one event does not affect the probability of the other event, the joint probability is calculated as the product of their individual probabilities:\n",
    "\n",
    "   P(A ∩ B) = P(A) * P(B)\n",
    "\n",
    "2. Dependent Events:\n",
    "If events A and B are dependent, meaning the occurrence of one event affects the probability of the other event, the joint probability is calculated using the conditional probability:\n",
    "\n",
    "   P(A ∩ B) = P(A | B) * P(B)\n",
    "\n",
    "   Here, P(A | B) represents the probability of event A occurring given that event B has already occurred, and P(B) represents the probability of event B occurring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb315547-6f87-46ff-9746-4547a11c69fe",
   "metadata": {},
   "source": [
    "**4. What is chain rule of probability?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad74124b-9033-4364-b75a-5ab62d6cefed",
   "metadata": {},
   "source": [
    "The chain rule of probability, also known as the multiplication rule, is a fundamental principle in probability theory that allows us to calculate the probability of the intersection of multiple events. It is based on the concept of conditional probability.\n",
    "\n",
    "According to the chain rule, the probability of the joint occurrence of multiple events can be calculated by multiplying the conditional probabilities of each event given the previous events in the sequence. Mathematically, the chain rule can be expressed as follows:\n",
    "\n",
    "P(A1 ∩ A2 ∩ A3 ∩ ... ∩ An) = P(A1) * P(A2 | A1) * P(A3 | A1 ∩ A2) * ... * P(An | A1 ∩ A2 ∩ ... ∩ An-1)\n",
    "\n",
    "In this formula, P(Ai) represents the probability of event Ai occurring, and P(Ai | A1 ∩ A2 ∩ ... ∩ Ai-1) represents the probability of event Ai occurring given that events A1, A2, ..., Ai-1 have already occurred.\n",
    "\n",
    "The chain rule is particularly useful when dealing with complex events that can be broken down into a sequence of simpler events. By applying the chain rule, we can calculate the overall probability of such complex events by considering the conditional probabilities of each individual event in the sequence.\n",
    "\n",
    "The chain rule is an important tool in probability calculations and is widely used in various applications, including Bayesian inference, decision theory, and statistical modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41466859-39a3-4a9d-bde4-80d51cd029f2",
   "metadata": {},
   "source": [
    "**5. What is conditional probability means? What is the formula of it?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfb32a7-d9fb-4f72-a3ba-ee78d0b01db1",
   "metadata": {},
   "source": [
    "Conditional probability is a measure of the probability of an event occurring given that another event has already occurred. It quantifies the likelihood of an event A happening, given that event B has occurred.\n",
    "\n",
    "The formula for conditional probability is:\n",
    "\n",
    "P(A | B) = P(A ∩ B) / P(B)\n",
    "\n",
    "In this formula, P(A | B) denotes the conditional probability of event A given event B, P(A ∩ B) represents the probability of the intersection of events A and B, and P(B) is the probability of event B occurring.\n",
    "\n",
    "In words, the formula can be understood as follows: the probability of event A occurring, given that event B has occurred, is equal to the probability of both events A and B occurring together divided by the probability of event B occurring.\n",
    "\n",
    "The concept of conditional probability allows us to adjust probabilities based on additional information or prior knowledge. It is a fundamental concept in probability theory and has applications in various fields, including statistics, machine learning, and decision-making."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843b705d-437b-4183-9e53-b96f05868537",
   "metadata": {},
   "source": [
    "**6. What are continuous random variables?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cd127f-52a7-44ec-a431-5f307eadde9d",
   "metadata": {},
   "source": [
    "Continuous random variables are variables that can take on any value within a specified range or interval. Unlike discrete random variables, which can only take on specific values, continuous random variables have an infinite number of possible values within their range.\n",
    "\n",
    "The values of continuous random variables are typically measured or observed quantities that can be expressed as real numbers. Examples of continuous random variables include height, weight, temperature, time, and distance. These variables can take on any value within their respective intervals, such as any real number between 0 and 1 for a probability value.\n",
    "\n",
    "The probability distribution of a continuous random variable is described by a probability density function (PDF), which assigns probabilities to intervals rather than specific values. The probability of a continuous random variable taking on a particular value is typically zero since there are infinitely many possible values.\n",
    "\n",
    "Continuous random variables are commonly used in statistical analysis, probability theory, and modeling real-world phenomena where measurements or observations are not restricted to discrete values. They play a crucial role in fields such as physics, engineering, economics, and many other scientific disciplines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5808e4df-3cdf-4c0d-b561-f8419553cf66",
   "metadata": {},
   "source": [
    "**7. What are Bernoulli distributions? What is the formula of it?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4976cca0-9812-4d0a-ad7b-35eda357d145",
   "metadata": {},
   "source": [
    "The Bernoulli distribution is a discrete probability distribution that models a random variable that can take only two possible outcomes, typically labeled as success (usually denoted by 1) or failure (usually denoted by 0). It is named after Jacob Bernoulli, a Swiss mathematician.\n",
    "\n",
    "The probability mass function (PMF) of a Bernoulli distribution is given by the following formula:\n",
    "\n",
    "P(X = k) = p^k * (1 - p)^(1-k)\n",
    "\n",
    "where:\n",
    "- P(X = k) is the probability of the random variable X taking the value k.\n",
    "- p is the probability of success (the probability of X being 1).\n",
    "- k is the value that X can take, which is either 0 or 1.\n",
    "\n",
    "The Bernoulli distribution is characterized by a single parameter, p, which represents the probability of success. The probability of failure is given by (1 - p). The expected value (mean) of a Bernoulli random variable is equal to p, and the variance is equal to p(1-p).\n",
    "\n",
    "The Bernoulli distribution is often used to model binary outcomes or events with only two possible outcomes, such as flipping a coin (heads or tails), success or failure of a product, yes or no answers, and many other situations where there are only two possible outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60039215-5fc7-4abb-bacb-7b80aed18a3a",
   "metadata": {},
   "source": [
    "**8. What is binomial distribution? What is the formula?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80e08d2-8f12-42a0-95c8-6501903ddaa1",
   "metadata": {},
   "source": [
    "The binomial distribution is a discrete probability distribution that models the number of successes in a fixed number of independent Bernoulli trials. It is used to calculate the probabilities of obtaining a certain number of successes in a specific number of trials.\n",
    "\n",
    "The formula for the probability mass function (PMF) of a binomial distribution is given by:\n",
    "\n",
    "P(X = k) = C(n, k) * p^k * (1 - p)^(n-k)\n",
    "\n",
    "where:\n",
    "- P(X = k) is the probability of getting exactly k successes in n trials.\n",
    "- C(n, k) is the binomial coefficient, also known as \"n choose k,\" which represents the number of ways to choose k successes from n trials and is calculated as C(n, k) = n! / (k! * (n - k)!).\n",
    "- p is the probability of success in each individual trial.\n",
    "- k is the number of successes.\n",
    "- n is the total number of trials.\n",
    "\n",
    "The binomial distribution is characterized by two parameters: n, the number of trials, and p, the probability of success in each trial. The expected value (mean) of a binomial distribution is equal to n * p, and the variance is equal to n * p * (1 - p)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e4bb08-7e8a-4092-832d-2d4028e5f208",
   "metadata": {},
   "source": [
    "**9. What is Poisson distribution? What is the formula?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a57cce-4487-40d7-8833-a5c4b9204108",
   "metadata": {},
   "source": [
    "The Poisson distribution is a discrete probability distribution that models the number of events that occur in a fixed interval of time or space, given the average rate of occurrence. It is often used to model rare events or events that occur randomly over time or space.\n",
    "\n",
    "The formula for the probability mass function (PMF) of a Poisson distribution is given by:\n",
    "\n",
    "P(X = k) = (e^(-λ) * λ^k) / k!\n",
    "\n",
    "where:\n",
    "- P(X = k) is the probability of observing k events.\n",
    "- e is Euler's number, approximately equal to 2.71828.\n",
    "- λ (lambda) is the average rate of events occurring in the given interval.\n",
    "- k is the number of events observed.\n",
    "\n",
    "The Poisson distribution is characterized by a single parameter λ, which represents the average rate of occurrence. The expected value (mean) and variance of a Poisson distribution are both equal to λ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1183c95d-e6ae-459f-96df-6050c64ca84e",
   "metadata": {},
   "source": [
    "**10. Define covariance.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b0c081-9384-4aeb-8aa0-27b346458c06",
   "metadata": {},
   "source": [
    "Covariance is a statistical measure that quantifies the relationship between two random variables. It measures how changes in one variable are associated with changes in another variable. Specifically, covariance indicates the extent to which two variables move together, either in a similar or opposite direction.\n",
    "\n",
    "Mathematically, the covariance between two random variables X and Y is calculated as the average of the products of their deviations from their respective means:\n",
    "\n",
    "Cov(X, Y) = E[(X - E[X])(Y - E[Y])]\n",
    "\n",
    "where Cov(X, Y) represents the covariance between X and Y, E[X] is the expected value (mean) of X, E[Y] is the expected value (mean) of Y, and the notation E[ ] denotes the expected value operator.\n",
    "\n",
    "The covariance can take positive, negative, or zero values, indicating different types of relationships between the variables:\n",
    "- Positive covariance: A positive covariance suggests that as one variable increases, the other variable tends to increase as well.\n",
    "- Negative covariance: A negative covariance suggests that as one variable increases, the other variable tends to decrease, and vice versa.\n",
    "- Zero covariance: A zero covariance indicates that there is no linear relationship between the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19272b65-6e84-417b-be42-34acec9108c5",
   "metadata": {},
   "source": [
    "**11. Define correlation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ba1838-4e79-4dde-a197-3580f06b02e8",
   "metadata": {},
   "source": [
    "Correlation is a statistical measure that quantifies the strength and direction of the linear relationship between two variables. It measures how closely the data points in a scatter plot adhere to a straight line. Correlation indicates the extent to which changes in one variable are associated with changes in another variable.\n",
    "\n",
    "The correlation coefficient, denoted by r, is a common measure of correlation. It takes values between -1 and +1, where:\n",
    "- A correlation coefficient of +1 indicates a perfect positive correlation, meaning that as one variable increases, the other variable increases proportionally.\n",
    "- A correlation coefficient of -1 indicates a perfect negative correlation, meaning that as one variable increases, the other variable decreases proportionally.\n",
    "- A correlation coefficient of 0 indicates no linear relationship between the variables.\n",
    "\n",
    "The formula for the correlation coefficient is:\n",
    "\n",
    "r = (Σ((X - X_mean)(Y - Y_mean))) / (√(Σ(X - X_mean)^2) √(Σ(Y - Y_mean)^2))\n",
    "\n",
    "where X and Y are the variables, X_mean and Y_mean are their respective means, and Σ represents the sum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ede53e9-a7d6-4fa2-843e-c02f2426a4b0",
   "metadata": {},
   "source": [
    "**12. Define sampling with replacement. Give example.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c476dd-8abc-43d0-b12b-46a178b3d799",
   "metadata": {},
   "source": [
    "Sampling with replacement, also known as sampling with repetition, is a method of selecting elements from a population or dataset where each selected element is returned to the population before the next selection. This means that the same element can be selected more than once in the sampling process.\n",
    "\n",
    "Example:\n",
    "Let's say we have a bag containing five colored balls: red, blue, green, yellow, and orange. We want to randomly select three balls from the bag using sampling with replacement. Here's how the process might unfold:\n",
    "\n",
    "1. We reach into the bag and randomly select a ball. We note down its color and put it back into the bag.\n",
    "   Example: We select a green ball.\n",
    "\n",
    "2. We reach into the bag again and randomly select another ball. We note down its color and put it back into the bag.\n",
    "   Example: We select a red ball.\n",
    "\n",
    "3. We repeat the process one more time.\n",
    "   Example: We select a green ball again.\n",
    "\n",
    "In this example, we sampled three balls from the bag using sampling with replacement. Notice that after each selection, we returned the selected ball back to the bag, allowing the possibility of selecting the same ball again in subsequent draws.\n",
    "\n",
    "Sampling with replacement is commonly used in statistical analysis and simulations, especially when dealing with finite populations or when we want to maintain the same distribution of elements throughout the sampling process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc69037-0959-42f1-b271-9e397cc2e766",
   "metadata": {},
   "source": [
    "**13. What is sampling without replacement? Give example.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd250ec-7723-49a5-b9b6-9a65a54c6e70",
   "metadata": {},
   "source": [
    "Sampling without replacement, also known as sampling without repetition, is a method of selecting elements from a population or dataset where each selected element is not returned to the population before the next selection. This means that once an element is selected, it is removed from the population and cannot be selected again in subsequent draws.\n",
    "\n",
    "Example:\n",
    "Let's say we have a deck of playing cards consisting of 52 cards (4 suits with 13 cards each), and we want to randomly select three cards from the deck using sampling without replacement. Here's how the process might unfold:\n",
    "\n",
    "1. We shuffle the deck to randomize the order of the cards.\n",
    "\n",
    "2. We reach into the deck and randomly select a card. We note down its value and suit and remove it from the deck.\n",
    "   Example: We select the 7 of hearts.\n",
    "\n",
    "3. We reach into the remaining deck and randomly select another card. We note down its value and suit and remove it from the deck.\n",
    "   Example: We select the Queen of diamonds.\n",
    "\n",
    "4. We repeat the process one more time.\n",
    "   Example: We select the 3 of spades.\n",
    "\n",
    "In this example, we sampled three cards from the deck using sampling without replacement. Once a card is selected, it is removed from the deck, reducing the number of available cards for subsequent selections.\n",
    "\n",
    "Sampling without replacement is commonly used in statistics and research when we want to ensure that each selected item is unique and avoid duplication in the sample. It is often employed when dealing with finite populations or when maintaining the independence of the sampled elements is important."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ef587b-627b-4cdd-ac17-9aa4d1f63d6b",
   "metadata": {},
   "source": [
    "**14. What is hypothesis? Give example.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a5b7b9-fe15-41fe-a24d-e19ea6d6c468",
   "metadata": {},
   "source": [
    "In the context of statistics and research, a hypothesis is a statement or assumption about a population or a phenomenon that is subject to testing and investigation. It is a tentative explanation or prediction about the relationship between variables or the outcome of an experiment.\n",
    "\n",
    "Example:\n",
    "Let's say a researcher is interested in investigating the effect of a new drug on reducing blood pressure. They might formulate the following hypothesis:\n",
    "\n",
    "Null Hypothesis (H0): The new drug has no effect on reducing blood pressure.\n",
    "\n",
    "Alternative Hypothesis (HA): The new drug has a significant effect on reducing blood pressure.\n",
    "\n",
    "In this example, the null hypothesis represents the default assumption or the absence of an effect, suggesting that the new drug does not have any impact on blood pressure. The alternative hypothesis, on the other hand, posits that the new drug does have a significant effect on reducing blood pressure.\n",
    "\n",
    "The researcher would collect data, conduct experiments, or perform statistical analysis to evaluate the evidence and make conclusions regarding the hypotheses. The purpose of hypothesis testing is to assess the validity of the null hypothesis and determine whether there is enough evidence to support the alternative hypothesis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
